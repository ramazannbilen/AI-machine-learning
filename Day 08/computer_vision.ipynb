{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5eVVFxTLpVGb"},"outputs":[],"source":["pip install opencv-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUvNtKu2pVGc"},"outputs":[],"source":["import cv2\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HjRuzl8_pVGd"},"outputs":[],"source":["input_1 = cv2.imread(\"input_1.jpg\")\n","cv2.imshow(\"Hello world\",input_1)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bh72eu4CpVGd","outputId":"499fda21-76e1-4972-cd7c-5d63d295464e"},"outputs":[],"source":["print ('Heiht of image', int(input_1.shape[0]),'pixels')\n","print ('Width of image', int(input_1.shape[1]),'pixels')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HSGIkx0YpVGe","outputId":"849843dd-8e5d-4e00-ed2c-f514bb0dc43d"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","checkBoard = np.zeros((9,9))\n","checkBoard[0::2,1::2]=1\n","checkBoard[1::2,0::2]=1\n","print(checkBoard)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54qCG1WkpVGf"},"outputs":[],"source":["import matplotlib.image as mpig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5HSW1r3pVGf","outputId":"e69131f8-2a60-49de-8657-8de464a51ee2"},"outputs":[],"source":["plt.imshow(checkBoard,cmap=\"gray\",interpolation=\"nearest\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"sNP5_ZETpVGf","jupyter":{"outputs_hidden":true},"outputId":"f93637b1-f5c8-46a3-cfb9-15ec12e19d05"},"outputs":[],"source":["from skimage import data\n","image_of_a_bush = data.lfw_subset()\n","image_of_a_bush = image_of_a_bush[0,:,:]\n","print(image_of_a_bush)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZO6hIuvpVGg","outputId":"be06ed26-75ca-4c83-8a82-e8f6d1a3e684"},"outputs":[],"source":["plt.figure(figsize=(3,3))\n","plt.imshow(image_of_a_bush,cmap=\"gray\",interpolation=\"nearest\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66WXO4G2pVGg","outputId":"004d5e55-f2ec-4764-997f-a1df952d8ffc"},"outputs":[],"source":["image = data.astronaut()\n","plt.imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx-jMk6EpVGh"},"outputs":[],"source":["image = cv2.imread(\"input_1.jpg\")\n","cv2.imshow(\"Original\",image)\n","cv2.waitKey()\n","\n","gray_image= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","cv2.imshow(\"Grayscale\",gray_image)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxUEaEZupVGh"},"outputs":[],"source":["img = cv2.imread(\"input_1.jpg\",0)\n","cv2.imshow(\"Grayscale\",img)\n","cv2.waitKey()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5DE2iqFpVGh","outputId":"db60374b-6b9a-4575-805d-61cea13889da"},"outputs":[],"source":["image = cv2.imread(\"input.jpg\")\n","B,G,R = image[0,0]\n","B,G,R = image[10,50]\n","print(B,G,R)\n","print(image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGJDcBkupVGi","outputId":"9452ee4d-f985-4a77-ccad-90ae7e67718f"},"outputs":[],"source":["gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","print(gray_img.shape)\n","print(gray_img[10,50])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lWvnhvzpVGi","outputId":"0b356b3b-0989-49e9-c627-d86c5258712d"},"outputs":[],"source":["gray_img[0,0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spdthWb0pVGi"},"outputs":[],"source":["image = cv2.imread(\"input.jpg\")\n","hsv_image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n","\n","cv2.imshow(\"HSV image\",hsv_image[:,:,:])\n","cv2.imshow(\"Hue channel\",hsv_image[:,:,0])\n","cv2.imshow(\"Saturation channel\",hsv_image[:,:,1])\n","cv2.imshow(\"Calue channel\",hsv_image[:,:,2])\n","cv2.waitKey()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJUOMHEOpVGi","outputId":"52e1736b-f406-4cde-f32c-be5c8f07c579"},"outputs":[],"source":["image = cv2.imread(\"input_1.jpg\")\n","B,G,R =cv2.split(image)\n","print(B.shape)\n","cv2.imshow(\"Red\",R)\n","cv2.imshow(\"Green\",G)\n","cv2.imshow(\"Blue\",B)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","merged = cv2.merge([B,G,R])\n","cv2.imshow(\"Merged\",merged)\n","merged= cv2.merge([B+100,G,R+100])\n","cv2.imshow(\"Merged with Blue Amplified\",merged)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XcQvJ1DpVGi"},"outputs":[],"source":["image = cv2.imread('input.jpg')\n","\n","height,width = image.shape[:2]\n","\n","quareter_height,quareter_width = height/4,width/4\n","\n","T = np.float32([[1,0,quareter_width],[0,1,quareter_height]])\n","\n","img_translation = cv2.warpAffine(image,T,(width,height))\n","cv2.imshow('Translation',img_translation)\n","cv2.waitKey()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_JtZgEoDpVGj"},"outputs":[],"source":["image = cv2.imread('input.jpg')\n","\n","height,width = image.shape[:2]\n","\n","rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),45,.5)\n","\n","rotated_image = cv2.warpAffine(image,rotation_matrix,(width,height))\n","\n","cv2.imshow('Rotated Image',rotated_image)\n","cv2.waitKey()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkc8sfQopVGj"},"outputs":[],"source":["image = cv2.imread('input_1.jpg',0)\n","\n","height,width = image.shape[:2]\n","\n","sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize = 5)\n","sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize = 5)\n","\n","cv2.imshow('Rotated Image',image)\n","cv2.waitKey(0)\n","cv2.imshow('Sobel X',sobel_x)\n","cv2.waitKey(0)\n","cv2.imshow('Sobel Y',sobel_y)\n","cv2.waitKey(0)\n","\n","sobel_OR = cv2.bitwise_or(sobel_x,sobel_y)\n","cv2.imshow('sobel_OR',sobel_OR)\n","cv2.waitKey(0)\n","\n","laplacian = cv2.Laplacian(image,cv2.CV_64F)\n","cv2.imshow('Laplacian',laplacian)\n","cv2.waitKey(0)\n","\n","canny = cv2.Canny(image,50,120)\n","cv2.imshow('Canny',canny)\n","cv2.waitKey(0)\n","\n","\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-IbFQdKpVGj","outputId":"00b5bd8f-c326-4c53-8317-59a3ebae7b45"},"outputs":[],"source":["def sketch(image):\n","    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","\n","    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n","    canny_edges = cv2.Canny(img_gray_blur,10,70)\n","    ret,mask = cv2.threshold(canny_edges,250,255,cv2.THRESH_BINARY_INV)\n","    return mask\n","\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    ret,frame = cap.read()\n","    cv2.imshow('Our live Sketcher',sketch(frame))\n","    if cv2.waitKey(1) == 13:\n","        break\n","cap.release()\n","cv2.destroyAllWindows()\n","print('done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFVCDZQfpVGk"},"outputs":[],"source":["image = cv2.imread(\"WaldoBeach.jpg\")\n","\n","cv2.imshow(\"Where is Waldo\",image)\n","cv2.waitKey(0)\n","gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","\n","template = cv2.imread(\"waldo.jpg\",0)\n","\n","result = cv2.matchTemplate(gray,template,cv2.TM_CCOEFF)\n","minVal,maxVal,minLoc,maxLoc = cv2.minMaxLoc(result)\n","\n","top_left = maxLoc\n","bottom_right =(top_left[0] + 50, top_left[1]+50)\n","cv2.rectangle(image,top_left,bottom_right,(0,0,255),5)\n","\n","cv2.imshow(\"Where is Waldo\",image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8kjuqaXpVGk","outputId":"351bfa5e-b9f3-4665-a999-cebc0d240095"},"outputs":[],"source":["plt.imshow(template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-S7xojNpVGk"},"outputs":[],"source":["import imutils\n","image = cv2.imread(\"input_1.jpg\")\n","cv2.imshow(\"Original\",image)\n","\n","flipped = cv2.flip(image,0)\n","cv2.imshow(\"Vertical Flip\",flipped)\n","\n","flipped = cv2.flip(image,1)\n","cv2.imshow(\"Horizontal Flip\",flipped)\n","\n","flipped = cv2.flip(image,-1)\n","cv2.imshow(\"Bot Flip\",flipped)\n","\n","cv2.waitKey()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AJo20JmpVGk"},"outputs":[],"source":["cap = cv2.VideoCapture(\"airplanes.mp4\")\n","\n","while True:\n","    ret,frame= cap.read()\n","    if ret:\n","        cv2.imshow(\"Demo\",frame)\n","    else:\n","        break\n","    key = cv2.waitKey(10)\n","    if key == ord(\"q\"):\n","        break\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qeOMBFaJpVGk"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","\n","while True:\n","    ret,frame= cap.read()\n","    if ret:\n","        cv2.imshow(\"Bendeniz\",frame)\n","    else:\n","        break\n","    key = cv2.waitKey(1)\n","    if key == ord(\"q\"):\n","        break\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQe_kvw2pVGk"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","\n","ret1,frame1 = cap.read()\n","ret2,frame2 = cap.read()\n","\n","while True:\n","    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n","    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n","    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n","\n","    diff = cv2.absdiff(frame1_blur,frame2_blur)\n","    cv2.imshow(\"Motion\",diff)\n","    frame1 = frame2\n","    ret,frame2 = cap.read()\n","    if not ret:\n","        cap.release()\n","        break\n","    key = cv2.waitKey(10)\n","    if key == ord(\"q\"):\n","        cap.release()\n","        break\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGc9tGiApVGl"},"outputs":[],"source":["cap = cv2.VideoCapture(\"cars.mp4\")\n","\n","ret1,frame1 = cap.read()\n","ret2,frame2 = cap.read()\n","\n","while True:\n","    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n","    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n","    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n","\n","    diff = cv2.absdiff(frame1_blur,frame2_blur)\n","    cv2.imshow(\"Motion\",diff)\n","    frame1 = frame2\n","    ret,frame2 = cap.read()\n","    if not ret:\n","        cap.release()\n","        break\n","    key = cv2.waitKey(10)\n","    if key == ord(\"q\"):\n","        cap.release()\n","        break\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1pVos3M0pVGl"},"outputs":[],"source":["cap = cv2.VideoCapture(\"airplanes.mp4\")\n","\n","ret1,frame1 = cap.read()\n","ret2,frame2 = cap.read()\n","\n","while True:\n","    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n","    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n","    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n","\n","    diff = cv2.absdiff(frame1_blur,frame2_blur)\n","    cv2.imshow(\"Motion\",diff)\n","    frame1 = frame2\n","    ret,frame2 = cap.read()\n","    if not ret:\n","        cap.release()\n","        break\n","    key = cv2.waitKey(10)\n","    if key == ord(\"q\"):\n","        cap.release()\n","        break\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8lAUuLDpVGl"},"outputs":[],"source":["cap = cv2.VideoCapture(\"airplanes.mp4\")\n","\n","ret1,frame1 = cap.read()\n","ret2,frame2 = cap.read()\n","\n","while True:\n","    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n","    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n","    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n","\n","    diff = cv2.absdiff(frame1_blur,frame2_blur)\n","\n","    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n","    final = cv2.dilate(thresh,None,iterations=2)\n","\n","    masked = cv2.bitwise_and(frame1,frame1,mask=thresh)\n","    white_pixels = np.sum(thresh) /255\n","\n","    rows,cols = thresh.shape\n","    total= rows*cols\n","    if white_pixels > 0.01*total:\n","        font = cv2.FONT_HERSHEY_SIMPLEX\n","        cv2.putText(frame1,\"Movement Detected - Hareket Var\",(10,50),font,1,(0,0,255),2,cv2.LINE_AA)\n","    cv2.imshow(\"Motion\",frame1)\n","    frame1=frame2\n","    ret,frame2 = cap.read()\n","    if not ret:\n","        break\n","    key = cv2.waitKey(10)\n","    if key == 27 or key == ord(\"q\"):\n","        break\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zlPQreyTpVGl","outputId":"bfa57b7f-f2ff-425f-9be4-4dddf72228a9"},"outputs":[],"source":["image = cv2.imread(\"bunchofshapes.jpg\")\n","cv2.imshow(\"Input Image\",image)\n","cv2.waitKey(0)\n","\n","gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n","\n","edged = cv2.Canny(gray,30,200)\n","cv2.imshow(\"Canny Edges\",edged)\n","cv2.waitKey(0)\n","\n","contours,hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n","cv2.imshow(\"Canny Edges After Contouring\",edged)\n","cv2.waitKey(0)\n","\n","print(\"Number of Contours found = \" + str(len(contours)))\n","\n","cv2.drawContours(image,contours,-1,(0,255,0),thickness=2)\n","\n","cv2.imshow(\"Contours\",image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTMU12WMpVGl","outputId":"e7caba2c-5ac2-4ce7-8b8e-1ebf8154427f"},"outputs":[],"source":["plt.imshow(cv2.imread(\"bunchofshapes.jpg\",0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dtlsFOWFpVGm"},"outputs":[],"source":["image = cv2.imread('soduku.jpg')\n","cv2.imshow('Original', image)\n","cv2.waitKey(0)\n","# Grayscale and Canny Edges extracted\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n","\n","# Run HoughLines using a rho accuracy of 1 pixel\n","# theta accuracy of np.pi / 180 which is 1 degree\n","# Our line threshold is set to 240 (number of points on line)\n","lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n","\n","# We iterate through each line and convert it to the format\n","# required by cv2.lines (i.e. requiring end points)\n","for line in lines:\n","    rho, theta = line[0]\n","    a = np.cos(theta)\n","    b = np.sin(theta)\n","    x0 = a * rho\n","    y0 = b * rho\n","    x1 = int(x0 + 1000 * (-b))\n","    y1 = int(y0 + 1000 * (a))\n","    x2 = int(x0 - 1000 * (-b))\n","    y2 = int(y0 - 1000 * (a))\n","    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n","\n","cv2.imshow('Hough Lines', image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NB2hvPeNpVGm"},"outputs":[],"source":["image = cv2.imread('opencv.jpg')\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","blur = cv2.medianBlur(gray, 5)\n","\n","circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 20)\n","\n","circles = np.uint16(np.around(circles))\n","\n","for i in circles[0,:]:\n","    # draw the outer circle\n","    cv2.circle(image,(i[0], i[1]), i[2], (0, 255, 0), 2)\n","\n","    # draw the center of the circle\n","    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n","\n","cv2.imshow('detected circles', image)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpSJmpxApVGm"},"outputs":[],"source":["# Read image\n","image = cv2.imread(\"Sunflowers.jpg\")\n","\n","# Set up the detector with default par ameters.\n","detector =cv2.SimpleBlobDetector_create()\n","\n","# Detect blobs.\n","keypoints = detector.detect(image)\n","\n","# Draw detected blobs as red circles.\n","# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n","# the circle corresponds to the size of blob\n","blank = np.zeros((1,1))\n","blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n","                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n","\n","# Show keypoints\n","cv2.imshow(\"Blobs\", blobs)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzBZINgvpVGn"},"outputs":[],"source":["# Read image\n","image = cv2.imread(\"Sunflowers.jpg\")\n","\n","# Set up the detector with default par ameters.\n","detector =cv2.SimpleBlobDetector_create()\n","\n","# Detect blobs.\n","keypoints = detector.detect(image)\n","\n","# Draw detected blobs as red circles.\n","# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n","# the circle corresponds to the size of blob\n","blank = np.zeros((1,1))\n","blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n","                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n","\n","# Show keypoints\n","cv2.imshow(\"Blobs\", blobs)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"660ZBSGQpVGn","outputId":"589b1696-9fa1-46ad-cb49-1daf4e197e62"},"outputs":[],"source":["\n","# classifier (XML file format) is stored\n","face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","\n","# Load our image then convert it to grayscale\n","image = cv2.imread('myself.jpg')\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# Our classifier returns the ROI of the detected face as a tuple\n","# It stores the top left coordinate and the bottom right coordiantes\n","faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No faces found\")\n","\n","# We iterate through our faces array and draw a rectangle\n","# over each face in faces\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n","    cv2.imshow('Face Detection', image)\n","    cv2.waitKey(0)\n","\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtomYqnxpVGn","outputId":"a348ce99-6ff7-48ba-efdb-9822214945e7"},"outputs":[],"source":["face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n","\n","img = cv2.imread('myself.jpg')\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","\n","# When no faces detected, face_classifier returns and empty tuple\n","if faces is ():\n","    print(\"No Face Found\")\n","\n","for (x,y,w,h) in faces:\n","    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n","    cv2.imshow('img',img)\n","    cv2.waitKey(0)\n","    roi_gray = gray[y:y+h, x:x+w]\n","    roi_color = img[y:y+h, x:x+w]\n","    eyes = eye_classifier.detectMultiScale(roi_gray)\n","    for (ex,ey,ew,eh) in eyes:\n","        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n","        cv2.imshow('img',img)\n","        cv2.waitKey(0)\n","\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgvwxQDfpVGn","outputId":"112623a4-b6ef-4a7c-cda0-83b539582d8f"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from time import sleep\n","face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n","def face_detector(img, size=0.5):\n","    # Convert image to grayscale\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n","    if faces is ():\n","        return img\n","    for (x,y,w,h) in faces:\n","        x = x - 50\n","        w = w + 50\n","        y = y - 50\n","        h = h + 50\n","        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n","        roi_gray = gray[y:y+h, x:x+w]\n","        roi_color = img[y:y+h, x:x+w]\n","        eyes = eye_classifier.detectMultiScale(roi_gray)\n","        sleep(.05)\n","        for (ex,ey,ew,eh) in eyes:\n","            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n","    img = cv2.flip(img,1)\n","    return img\n","cap = cv2.VideoCapture(0)\n","while True:\n","    ret, frame = cap.read()\n","    cv2.imshow('Our Face Extractor', face_detector(frame))\n","    if cv2.waitKey(1) == 13: #13 is the Enter Key\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1711573338458,"user":{"displayName":"Meltem UÃ§ar","userId":"06415093256480859049"},"user_tz":360},"id":"wMqW0ro-pVGn"},"outputs":[],"source":["#pip install opencv-contrib-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQZYruJrpVGo","outputId":"dc80359a-0731-44c6-868f-66fd98fd1554"},"outputs":[],"source":["face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n","def face_extractor(img):\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    faces = face_classifier.detectMultiScale(gray,1.3,5)\n","    if faces is ():\n","        return None\n","    for (x,y,w,h) in faces:\n","        cropped_face = img[y:y+h,x:x+w]\n","    return cropped_face\n","cap = cv2.VideoCapture(0)\n","count = 0\n","while True:\n","    ret,frame = cap.read()\n","    if face_extractor(frame) is not None:\n","        count += 1\n","        face = cv2.resize(face_extractor(frame),(200,200))\n","        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n","        file_name_path = './faces/user/' + str(count) +'.jpg'\n","        cv2.imwrite(file_name_path,face)\n","        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n","        cv2.imshow(\"Face Cropper\",face)\n","    else:\n","        print(\"Face not found\")\n","        pass\n","    if cv2.waitKey(1) == 13 or count ==100:\n","        break\n","cap.release()\n","cv2.destroyAllWindows()\n","print('Collecting Samples Complete')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"avTpmEk0pVGo","outputId":"c04e2241-fcd6-48a2-b495-51c239a94b1c"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from os import listdir\n","from os.path import isfile,join\n","\n","data_path = './faces/user/'\n","onlyfiles =[f for f in listdir(data_path) if isfile(join(data_path,f))]\n","\n","Training_Data,Labels = [],[]\n","\n","for i,files in enumerate(onlyfiles):\n","    image_path = data_path + onlyfiles[i]\n","    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n","    Training_Data.append(np.asarray(images,dtype = np.uint8))\n","    Labels.append(i)\n","\n","Labels = np.asarray(Labels,dtype = np.int32)\n","model = cv2.face.LBPHFaceRecognizer_create()\n","\n","model.train(np.asarray(Training_Data),np.asarray(Labels))\n","print(\"Model Trained Succesfully\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6QTvwjIpVGo","outputId":"34c747a7-2dd3-4d4d-ddc7-3b70bc24249f"},"outputs":[],"source":["face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n","def face_extractor(img, size = 0.5):\n","    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    faces = face_classifier.detectMultiScale(gray,1.3,5)\n","    if faces is ():\n","        return img,[]\n","    for (x,y,w,h) in faces:\n","        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n","        roi = img[y:y+h, x:x+w]\n","        roi = cv2.resize(roi,(200,200))\n","    return img,roi\n","cap = cv2.VideoCapture(0)\n","while True:\n","    ret,frame = cap.read()\n","    image,face = face_extractor(frame)\n","    try:\n","        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n","        results = model.predict(face)\n","        if results[1]<500:\n","            confidence = int(100 * (1-(results[1])/400))\n","            display_string = str(confidence) + '% sure this guy is myself'\n","        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n","        if confidence > 75:\n","            cv2.putText(image,\"Unlocked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n","            cv2.imshow(\"Face Recognition\",image)\n","        else:\n","            cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n","            cv2.imshow(\"Face Recognition\",image)\n","    except:\n","        cv2.putText(image,\"No Face Found\" ,(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n","        cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n","        cv2.imshow(\"Face Recognition\",image)\n","    if cv2.waitKey(1) == 13:\n","        cap.release()\n","        break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXcvuNeLpVGo","outputId":"4b52ed70-9629-4d7a-d597-8aaa3b22823c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ry1ePvJpVGo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYObKLnwpVGp"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
